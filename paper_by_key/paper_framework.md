# Papers with Keyword: framework

- [OS-Sentinel: Towards Safety-Enhanced Mobile GUI Agents via Hybrid Validation in Realistic Workflows](https://arxiv.org/abs/2510.24411)
    - Qiushi Sun, Mukai Li, Zhoumianze Liu, Zhihui Xie, Fangzhi Xu, Zhangyue Yin, Kanzhi Cheng, Zehao Li, Zichen Ding, Qi Liu, Zhiyong Wu, Zhuosheng Zhang, Ben Kao, Lingpeng Kong
    - ğŸ›ï¸ Institutions: The University of Hong Kong, Fudan University, Shanghai AI Laboratory, Nanyang Technological University â˜¼Nanjing University, Shanghai Jiao Tong University
    - ğŸ“… Date: Dec. 9, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Mobile]
    - ğŸ”‘ Key: [benchmark], [evaluation], [risk], [framework]
    - ğŸ“– TLDR: VLM agents show human-like capability in mobile environments, but pose significant security risks, including system compromise and privacy leakage. Addressing the challenge of detecting these unsafe operations, this paper introduce a dynamic sandbox **MobileRisk-Live** and safety benchmark **MobileRisk**. Based on this, they propose **OS-Sentinel**, a novel hybrid framework combining a Formal Verifier for system-level violations and a VLM-based Contextual Judge. [Github](https://github.com/OS-Copilot/OS-Sentinel)

- [VeriOS: Query-Driven Proactive Human-Agent-GUI Interaction for Trustworthy OS Agents](https://arxiv.org/pdf/2509.07553)
    - Zheng Wu, Heyuan Huang, Xingyu Lou, Xiangmou Qu, Pengzhou Cheng, Zongru Wu, Weiwen Liu, Weinan Zhang, Jun Wang, Zhaoxiang Wang, Zhuosheng Zhang
    - ğŸ›ï¸ Institutions: Shanghai Jiao Tong University, OPPO
    - ğŸ“… Date: Sept. 17, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Mobile], [web]
    - ğŸ”‘ Key: [framework], [untrustworthy], [dataset]
    - ğŸ“– TLDR: Most existing OS agents are designed for idealized settings, whereas real-world environments often present untrustworthy conditions. To mitigate risks of over-execution in such scenarios, this work proposes a query-driven human-agent-GUI interaction framework that enables OS agents to decide when to query humans for more reliable task completion. This work also introduce VeriOS-Agent trained with a two-stage learning paradigm that falicitate the decoupling and utilization of meta-knowledge. Concretely, VeriOS-Agent autonomously executes actions in normal conditions while proactively querying humans in untrustworthy scenarios. [Github](https://github.com/Wuzheng02/VeriOS)

- [HAICOSYSTEM: An Ecosystem for Sandboxing Safety Risks in Human-AI Interactions](https://arxiv.org/abs/2409.16427)
    - Xuhui Zhou, Hyunwoo Kim, Faeze Brahman, Liwei Jiang, Hao Zhu, Ximing Lu, Frank Xu, Bill Yuchen Lin, Yejin Choi, Niloofar Mireshghallah, Ronan Le Bras, Maarten Sap
    - ğŸ›ï¸ Institutions: Carnegie Mellon University, Allen Institute for AI
    - ğŸ“… Date: Aug. 30, 2025
    - ğŸ“‘ Publisher: COLM 2025
    - ğŸ’» Env: [Misc]
    - ğŸ”‘ Key: [risk], [evaluation], [framework], [benchmark]
    - ğŸ“– TLDR: HAICOSYSTEM is a framework that assesses AI agent safety in complex social interactions through a modular sandbox. It features a multi-dimensional evaluation covering operational, content, societal, and legal risks. Simulating over 8,000 interactions across 132 scenarios in seven domains, the study finds that state-of-the-art LLMs pose safety risks in 62% of cases, especially during tool use with malicious users. This underscores the critical need to address safety in dynamic human-AI-environment interactions. [Github](https://github.com/XuhuiZhou/HAICosystem)

- [Toward a Human-Centered Evaluation Framework for Trustworthy LLM-Powered GUI Agents](https://arxiv.org/abs/2504.17934)
    - Chaoran Chen, Zhiping Zhang, Ibrahim Khalilov, Bingcan Guo, Simret A Gebreegziabher, Yanfang Ye, Ziang Xiao, Yaxing Yao, Tianshi Li, Toby Jia-Jun Li
    - ğŸ›ï¸ Institutions: University of Notre Dame, Virginia Tech, University of Washington, Northeastern University
    - ğŸ“… Date: Jun. 5, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Misc]
    - ğŸ”‘ Key: [framework], [risk], [survey], [privacy]
    - ğŸ“– TLDR: This paper identifies three key risks, distinguishing them from traditional automation and general autonomous agents. Current evaluations prioritize performance, largely overlooking privacy and security. We review existing metrics and outline five challenges in using human evaluators. To address this, we advocate for a human-centered evaluation framework. This framework must incorporate risk assessments, enhance user awareness via in-context consent, and embed privacy and security considerations directly into agent design and evaluation.

- [MLA-Trust: Benchmarking Trustworthiness of Multimodal LLM Agents in GUI Environments](https://arxiv.org/abs/2506.01616)
    - Xiao Yang, Jiawei Chen, Jun Luo, Zhengwei Fang, Yinpeng Dong, Hang Su, Jun Zhu
    - ğŸ›ï¸ Institutions: Tsinghua University, East China Normal University
    - ğŸ“… Date: Jun. 2, 2025
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Mobile], [Web]
    - ğŸ”‘ Key: [benchmark], [evaluation], [framework], [trustworthiness]
    - ğŸ“– TLDR: Multimodal LLM-based agents (MLAs) integrate vision, language, and action for unprecedented autonomy in GUI applications, but introduce critical trustworthiness challenges due to their ability to modify digital states. Existing benchmarks are insufficient. This work introduces MLA-Trust, the first unified framework evaluating MLA trustworthiness across four dimensions: truthfulness, controllability, safety, and privacy, using realistic web and mobile tasks. [Github](https://github.com/thu-ml/MLA-Trust)

- [WebOlympus: An Open Platform for Web Agents on Live Websites](https://aclanthology.org/2024.emnlp-demo.20/)
    - Boyuan Zheng, Boyu Gou, Scott Salisbury, Zheng Du, Huan Sun, Yu Su
    - ğŸ›ï¸ Institutions: OSU
    - ğŸ“… Date: Nov. 12, 2024
    - ğŸ“‘ Publisher: EMNLP 2024
    - ğŸ’» Env: [Web]
    - ğŸ”‘ Key: [framework], [platform]
    - ğŸ“– TLDR: This paper introduces *WebOlympus*, an open platform designed to facilitate the research and deployment of web agents on live websites. It features a user-friendly Chrome extension interface, allowing users without programming expertise to operate web agents with minimal effort. The platform incorporates a **safety monitor** module to prevent harmful actions through human supervision or model-based control, supporting applications such as annotation interfaces for web agent trajectories and data crawling.

- [A Trembling House of Cards? Mapping Adversarial Attacks against Language Agents](https://arxiv.org/pdf/2402.10196)
    - Lingbo Mo, Zeyi Liao, Boyuan Zheng, Yu Su, Chaowei Xiao, Huan Sun
    - ğŸ›ï¸ Institutions: OSU, UWM
    - ğŸ“… Date: Feb. 15, 2024
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Misc]
    - ğŸ”‘ Key: [attack], [framework], [evaluation]
    - ğŸ“– TLDR: This paper introduces a conceptual framework to assess and understand adversarial vulnerabilities in language agents, dividing the agent structure into three componentsâ€”Perception, Brain, and Action. It discusses 12 specific adversarial attack types that exploit these components, ranging from input manipulation to complex backdoor and jailbreak attacks. The framework provides a basis for identifying and mitigating risks before the widespread deployment of these agents in real-world applications. [Github](https://github.com/OSU-NLP-Group/AgentAttack)
