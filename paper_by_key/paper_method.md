# Papers with Keyword: method

- [Safeguarding Mobile GUI Agent via Logic-based Action Verification](https://arxiv.org/abs/2503.18492)
    - Jungjae Lee, Dongjae Lee, Chihun Choi, Youngmin Im, Jaeyoung Wi, Kihong Heo, Sangeun Oh, Sunjae Lee, Insik Shin
    - ğŸ›ï¸ Institutions: KAIST, Korea University, Sungkyunkwan University
    - ğŸ“… Date: Sept. 11, 2025
    - ğŸ“‘ Publisher: ACM MOBICOM '25
    - ğŸ’» Env: [Mobile]
    - ğŸ”‘ Key: [method], [evaluation], [verification]
    - ğŸ“– TLDR: we introduce VeriSafe Agent (VSA): a formal verification system that serves as a logically grounded safeguard for Mobile GUI Agents. VSA deterministically ensures that an agent's actions strictly align with user intent before executing the action. At its core, VSA introduces a novel autoformalization technique that translates natural language user instructions into a formally verifiable specification. This enables runtime, rule-based verification of agent's actions, detecting erroneous actions even before they take effect. [Github](https://github.com/VeriSafeAgent/VeriSafeAgent)

- [Improved Large Language Model Jailbreak Detection via Pretrained Embeddings](https://arxiv.org/pdf/2412.01547)
    - Erick Galinkin, Martin Sablotny
    - ğŸ›ï¸ Institutions: NVIDIA,
    - ğŸ“… Date: Dec. 2, 2024
    - ğŸ“‘ Publisher: arXiv
    - ğŸ’» Env: [Misc]
    - ğŸ”‘ Key: [method], [risk], [injection], [jailbreaking]
    - ğŸ“– TLDR: The adoption of LLMs requires robust security against attacks like prompt injection and jailbreaking, which aim to bypass safety policies. To prevent LLMs from generating harmful content or taking undesirable actions, owners must implement safeguards during training and use additional blocking tools. Detecting jailbreaking prompts is crucial. This work proposes a novel and superior approach for jailbreak detection by combining text embeddings optimized for retrieval with traditional machine learning classification algorithms.
